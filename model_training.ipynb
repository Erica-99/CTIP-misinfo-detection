{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "872d5116",
   "metadata": {},
   "source": [
    "# Misinformation Detection\n",
    "### Model Training Notebook\n",
    "\n",
    "*Session 20 Group 4*\n",
    "*Erica, Sahan, Dinuka*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4baea8",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1c142c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import STOPWORDS\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e5c5e9",
   "metadata": {},
   "source": [
    "Read in data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5b1cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the reason why jade helm is obama favorite con...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us president donald trump revised hardline pol...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brazilian congressional report recommended on ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ah the simpsons the hilarious animated show th...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>says former fbi director james comey admitted ...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  the reason why jade helm is obama favorite con...  fake\n",
       "1  us president donald trump revised hardline pol...  real\n",
       "2  brazilian congressional report recommended on ...  real\n",
       "3  ah the simpsons the hilarious animated show th...  fake\n",
       "4  says former fbi director james comey admitted ...  fake"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/processed_dataset.csv\", index_col=0)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bf95af",
   "metadata": {},
   "source": [
    "Define stopwords to be used for the whole file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b79ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update(['said', 'aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'])\n",
    "stopwords = list(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd075a9",
   "metadata": {},
   "source": [
    "### Manually Extracted Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98347b4",
   "metadata": {},
   "source": [
    "Using specific highly label-correlated bigrams. These are sourced from the data visualisation notebook.\n",
    "\n",
    "\"president donald\", \"washington reuters\", \"told reporters\", \"told reuters\", \"house representatives\", \"us president\", \"getty images\", \"image via\", \"featured image\" are all probably significantly correlated enough to consider using them for features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38b02959",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_BIGRAMS = [\n",
    "    (\"president\", \"donald\"),\n",
    "    (\"washington\", \"reuters\"),\n",
    "    (\"told\", \"reporters\"),\n",
    "    (\"told\", \"reuters\"),\n",
    "    (\"house\", \"representatives\"),\n",
    "    (\"us\", \"president\"),\n",
    "    (\"getty\", \"images\"),\n",
    "    (\"image\", \"via\"),\n",
    "    (\"featured\", \"image\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cff0d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>president_donald</th>\n",
       "      <th>washington_reuters</th>\n",
       "      <th>told_reporters</th>\n",
       "      <th>told_reuters</th>\n",
       "      <th>house_representatives</th>\n",
       "      <th>us_president</th>\n",
       "      <th>getty_images</th>\n",
       "      <th>image_via</th>\n",
       "      <th>featured_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the reason why jade helm is obama favorite con...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us president donald trump revised hardline pol...</td>\n",
       "      <td>real</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brazilian congressional report recommended on ...</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ah the simpsons the hilarious animated show th...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>says former fbi director james comey admitted ...</td>\n",
       "      <td>fake</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  president_donald  \\\n",
       "0  the reason why jade helm is obama favorite con...  fake                 0   \n",
       "1  us president donald trump revised hardline pol...  real                 1   \n",
       "2  brazilian congressional report recommended on ...  real                 0   \n",
       "3  ah the simpsons the hilarious animated show th...  fake                 0   \n",
       "4  says former fbi director james comey admitted ...  fake                 0   \n",
       "\n",
       "   washington_reuters  told_reporters  told_reuters  house_representatives  \\\n",
       "0                   0               0             0                      0   \n",
       "1                   0               0             0                      0   \n",
       "2                   0               0             0                      0   \n",
       "3                   0               0             0                      0   \n",
       "4                   0               0             0                      0   \n",
       "\n",
       "   us_president  getty_images  image_via  featured_image  \n",
       "0             0             0          0               1  \n",
       "1             1             0          0               0  \n",
       "2             0             0          0               0  \n",
       "3             0             0          1               1  \n",
       "4             0             0          0               0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def count_target_bigrams(text, target_bigrams):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    bigrams_in_text = list(ngrams(tokens, 2))\n",
    "    bigram_counts = Counter(bigrams_in_text)\n",
    "    \n",
    "    return {f\"{w1}_{w2}\": bigram_counts.get((w1, w2), 0) for (w1, w2) in target_bigrams}\n",
    "\n",
    "bigram_features_df = dataset['text'].apply(lambda x: count_target_bigrams(x, TARGET_BIGRAMS)).apply(pd.Series)\n",
    "\n",
    "expanded_dataset = pd.concat([dataset, bigram_features_df], axis=1)\n",
    "expanded_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "304e9f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n",
      "Precision: 0.90\n",
      "Recall: 0.32\n",
      "F1 Score: 0.47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "bigram_feature_cols = [f\"{w1}_{w2}\" for w1, w2 in TARGET_BIGRAMS]\n",
    "\n",
    "label_map = {'fake': 0, 'real': 1}\n",
    "expanded_dataset['label_encoded'] = expanded_dataset['label'].map(label_map)\n",
    "\n",
    "X = expanded_dataset[bigram_feature_cols].fillna(0)\n",
    "scaler = StandardScaler() # Scaler is used since logistic regression can be sensitive to large differences in scale.\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "y = expanded_dataset['label_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17, stratify=y)\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:0.2f}\")\n",
    "print(f\"Precision: {precision:0.2f}\")\n",
    "print(f\"Recall: {recall:0.2f}\")\n",
    "print(f\"F1 Score: {f1:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadc7b5",
   "metadata": {},
   "source": [
    "Pretty much as good as you could expect for such a simplistic feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c93439",
   "metadata": {},
   "source": [
    "### rfc Model with TF-IDF alongside the manually-extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f716de1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "Precision: 0.93\n",
      "Recall: 0.89\n",
      "F1 Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Custom transformer to extract the text column\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "\n",
    "# Custom transformer to extract the manually-extracted feature columns\n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, keys):\n",
    "        self.keys = keys\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.keys]\n",
    "\n",
    "manual_feature_columns = [f\"{w1}_{w2}\" for w1, w2 in TARGET_BIGRAMS]\n",
    "\n",
    "# TF-IDF Vectorizer pipeline\n",
    "text_pipeline = Pipeline([\n",
    "    ('selector', TextSelector('text')),\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2), min_df=5, stop_words=stopwords)) # Min_df means the uni/bigram must appear in at least 5 documents to be considered.\n",
    "])\n",
    "\n",
    "# Manual features pipeline\n",
    "manual_pipeline = Pipeline([\n",
    "    ('selector', NumberSelector(manual_feature_columns)),\n",
    "    ('scaler', StandardScaler()) # Scaler is used since logistic regression can be sensitive to large differences in scale.\n",
    "])\n",
    "\n",
    "\n",
    "combined_features = FeatureUnion([\n",
    "    ('text_features', text_pipeline),\n",
    "    ('manual_features', manual_pipeline)\n",
    "])\n",
    "\n",
    "\n",
    "rfc_pipeline = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "X = expanded_dataset[['text'] + manual_feature_columns]\n",
    "y = expanded_dataset['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17, stratify=y)\n",
    "\n",
    "\n",
    "rfc_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = rfc_pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label='real')\n",
    "recall = recall_score(y_test, y_pred, pos_label='real')\n",
    "f1 = f1_score(y_test, y_pred, pos_label='real')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:0.2f}\")\n",
    "print(f\"Precision: {precision:0.2f}\")\n",
    "print(f\"Recall: {recall:0.2f}\")\n",
    "print(f\"F1 Score: {f1:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1249be1",
   "metadata": {},
   "source": [
    "### Compare to just a TF-IDF logistic regression model without extra features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021db581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "Precision: 0.93\n",
      "Recall: 0.88\n",
      "F1 Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=5, stop_words=stopwords)\n",
    "tfidf_matrix = vectorizer.fit_transform(dataset['text'])\n",
    "\n",
    "X = tfidf_matrix\n",
    "y = dataset['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17, stratify=y)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label='real')\n",
    "recall = recall_score(y_test, y_pred, pos_label='real')\n",
    "f1 = f1_score(y_test, y_pred, pos_label='real')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:0.2f}\")\n",
    "print(f\"Precision: {precision:0.2f}\")\n",
    "print(f\"Recall: {recall:0.2f}\")\n",
    "print(f\"F1 Score: {f1:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be76bfcf",
   "metadata": {},
   "source": [
    "Basically the same results, with ever-so-slightly worse recall. Overall, manual extraction like this does not seem worth it at least with Logistic Regression.\n",
    "\n",
    "What about another type of model like Random Forest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e60afd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Hybrid Pipeline -------\n",
      "Accuracy: 0.81\n",
      "Precision: 0.95\n",
      "Recall: 0.62\n",
      "F1 Score: 0.75\n",
      "------- TF-IDF Pipeline -------\n",
      "Accuracy: 0.82\n",
      "Precision: 0.98\n",
      "Recall: 0.62\n",
      "F1 Score: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ---------- Hybrid ------------\n",
    "# Uses the rest of the pipeline defined earlier\n",
    "rfc_hybrid_pipeline = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('clf', RandomForestClassifier(n_estimators=300, max_depth=20)) # Limit to top 20k words to make it not take forever\n",
    "])\n",
    "\n",
    "X_hybrid = expanded_dataset[['text'] + manual_feature_columns]\n",
    "y_hybrid = expanded_dataset['label']\n",
    "\n",
    "X_train_hybrid, X_test_hybrid, y_train_hybrid, y_test_hybrid = train_test_split(X_hybrid, y_hybrid, test_size=0.2, random_state=17, stratify=y_hybrid)\n",
    "\n",
    "rfc_hybrid_pipeline.fit(X_train_hybrid, y_train_hybrid)\n",
    "\n",
    "y_pred_hybrid = rfc_hybrid_pipeline.predict(X_test_hybrid)\n",
    "\n",
    "# -------- Just TF-IDF ----------\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=5, stop_words=stopwords)\n",
    "tfidf_matrix = vectorizer.fit_transform(dataset['text'])\n",
    "\n",
    "X_tfidf = tfidf_matrix\n",
    "y_tfidf = dataset['label']\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y_tfidf, test_size=0.2, random_state=17, stratify=y_tfidf)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200, max_depth=20)\n",
    "rfc.fit(X_tfidf, y_tfidf)\n",
    "\n",
    "y_pred_tfidf = rfc.predict(X_test_tfidf)\n",
    "\n",
    "# --------- EVAL -------------\n",
    "\n",
    "accuracy_hybrid = accuracy_score(y_test_hybrid, y_pred_hybrid)\n",
    "precision_hybrid = precision_score(y_test_hybrid, y_pred_hybrid, pos_label='real')\n",
    "recall_hybrid = recall_score(y_test_hybrid, y_pred_hybrid, pos_label='real')\n",
    "f1_hybrid = f1_score(y_test_hybrid, y_pred_hybrid, pos_label='real')\n",
    "\n",
    "print(\"------- Hybrid Pipeline -------\")\n",
    "print(f\"Accuracy: {accuracy_hybrid:0.2f}\")\n",
    "print(f\"Precision: {precision_hybrid:0.2f}\")\n",
    "print(f\"Recall: {recall_hybrid:0.2f}\")\n",
    "print(f\"F1 Score: {f1_hybrid:0.2f}\")\n",
    "\n",
    "accuracy_tfidf = accuracy_score(y_test_tfidf, y_pred_tfidf)\n",
    "precision_tfidf = precision_score(y_test_tfidf, y_pred_tfidf, pos_label='real')\n",
    "recall_tfidf = recall_score(y_test_tfidf, y_pred_tfidf, pos_label='real')\n",
    "f1_tfidf = f1_score(y_test_tfidf, y_pred_tfidf, pos_label='real')\n",
    "\n",
    "print(\"------- TF-IDF Pipeline -------\")\n",
    "print(f\"Accuracy: {accuracy_tfidf:0.2f}\")\n",
    "print(f\"Precision: {precision_tfidf:0.2f}\")\n",
    "print(f\"Recall: {recall_tfidf:0.2f}\")\n",
    "print(f\"F1 Score: {f1_tfidf:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5989a7aa",
   "metadata": {},
   "source": [
    "Somewhat poor results but they were also around the same level of effectiveness, further supporting that the manual feature extraction is not worth doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38888c",
   "metadata": {},
   "source": [
    "### Models using semantic embeddings for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33809d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "semantic_dataset = dataset\n",
    "semantic_dataset['tokens'] = semantic_dataset['text'].apply(word_tokenize)\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=semantic_dataset['tokens'],\n",
    "    vector_size=128,\n",
    "    window=5,\n",
    "    min_count=5, # At least 5 instances of the word\n",
    "    workers=4,\n",
    "    sg=1  # Using skip gram because I suspect it will work better than CBOW here.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b146fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Random Forest Classifier -------\n",
      "Accuracy: 0.89\n",
      "Precision: 0.91\n",
      "Recall: 0.85\n",
      "F1 Score: 0.88\n",
      "------- Logistic Regression -------\n",
      "Accuracy: 0.89\n",
      "Precision: 0.91\n",
      "Recall: 0.85\n",
      "F1 Score: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the average vector in a document from all the word vectors\n",
    "def document_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "    \n",
    "semantic_dataset['doc_vector'] = semantic_dataset['tokens'].apply(lambda tokens: document_vector(tokens, w2v_model))\n",
    "\n",
    "X = np.vstack(semantic_dataset['doc_vector'].to_numpy())\n",
    "y = semantic_dataset['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17)\n",
    "\n",
    "rfc_model = RandomForestClassifier(n_estimators=200, max_depth=20)\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "rfc_model.fit(X_train, y_train)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rfc = rfc_model.predict(X_test)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "accuracy_rfc = accuracy_score(y_test, y_pred_rfc)\n",
    "precision_rfc = precision_score(y_test, y_pred_rfc, pos_label='real')\n",
    "recall_rfc = recall_score(y_test, y_pred_rfc, pos_label='real')\n",
    "f1_rfc = f1_score(y_test, y_pred_rfc, pos_label='real')\n",
    "\n",
    "print(\"------- Random Forest Classifier -------\")\n",
    "print(f\"Accuracy: {accuracy_rfc:0.2f}\")\n",
    "print(f\"Precision: {precision_rfc:0.2f}\")\n",
    "print(f\"Recall: {recall_rfc:0.2f}\")\n",
    "print(f\"F1 Score: {f1_rfc:0.2f}\")\n",
    "\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr, pos_label='real')\n",
    "recall_lr = recall_score(y_test, y_pred_lr, pos_label='real')\n",
    "f1_lr = f1_score(y_test, y_pred_lr, pos_label='real')\n",
    "\n",
    "print(\"------- Logistic Regression -------\")\n",
    "print(f\"Accuracy: {accuracy_lr:0.2f}\")\n",
    "print(f\"Precision: {precision_lr:0.2f}\")\n",
    "print(f\"Recall: {recall_lr:0.2f}\")\n",
    "print(f\"F1 Score: {f1_lr:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6e309",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "Clustering will likely be done most effectively by using semantic embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4f4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CTIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
